{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Tensorflow intro\n",
    "\n",
    "This tutorial shows the basic usage of tensorflow to train neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Read data and convert them to numerical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=20000, n_features=8, n_informative=5, \n",
    "                           n_redundant=0, n_classes=2, random_state=1) #syntentic dataset \n",
    "\n",
    "#ndicates the number of informative features: predicting the target variableative\n",
    "#redundant feat: linear comnos of info feat\n",
    "#classes: target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#This means the train and test sets will have the same proportion of class labels as the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (12800, 8), target_ratio: 0.502\n",
      "test size: (4000, 8), target_ratio: 0.501\n",
      "dev size: (3200, 8), target_ratio: 0.502\n"
     ]
    }
   ],
   "source": [
    "print('train size: {}, target_ratio: {:.3f}'.format(X_train.shape, np.mean(y_train)))\n",
    "print('test size: {}, target_ratio: {:.3f}'.format(X_test.shape, np.mean(y_test)))\n",
    "print('dev size: {}, target_ratio: {:.3f}'.format(X_dev.shape, np.mean(y_dev)))\n",
    "\n",
    "#ukáže vyváženost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very useful documentations with many examples and detailed explanation of everything you might need:\n",
    " - https://www.tensorflow.org/api_docs/python/tf/keras/\n",
    " - https://keras.io/api/\n",
    "\n",
    "Contain everything about:\n",
    "  - Model building: Activations, Losses, Optimizers, Regularization\n",
    "  - Data processing\n",
    "  - Pretrained models and datasets\n",
    "  - Automatic differentiation\n",
    "  - ...\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model speficication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three APIs for building the model\n",
    "   - sequential - easy to code, but less flexible - we will use it sometimes\n",
    "   - functional - flexible and still easy to code - we will use it the most\n",
    "   - model subclassing - rather complicated and not very much used - we will skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/sequential_model)\n",
    "\n",
    "Easy to code but <span style=\"color:red\"> NOT </span> appropriate when:\n",
    "\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential API and the Functional API are two different ways to create and define models in TensorFlow/Keras, each with its own strengths and use cases.\n",
    "\n",
    "### Sequential API:\n",
    "- **Simple and Linear**: The Sequential API is straightforward and allows you to create models layer-by-layer in a linear manner.\n",
    "- **For Simple Models**: It's ideal for building simple models where the data flows sequentially through the layers, such as feedforward neural networks or CNNs with a single input and output.\n",
    "- **Limited Flexibility**: It has limited flexibility because it only supports models with a single input and single output. You cannot create models with branching or merging layers using the Sequential API.\n",
    "- **Convenient for Beginners**: It's often preferred by beginners due to its simplicity and ease of use.\n",
    "\n",
    "### Functional API:\n",
    "- **Flexible and Powerful**: The Functional API is more flexible and powerful, allowing you to create models with complex network architectures, including multiple inputs and outputs, branching, and merging layers.\n",
    "- **For Complex Models**: It's suitable for building more complex models, such as models with residual connections, multi-input/multi-output models, and models with shared layers.\n",
    "- **Explicit Input and Output Handling**: In the Functional API, you explicitly define the input and output layers, making it easier to work with multiple inputs and outputs.\n",
    "- **Better for Research and Advanced Users**: It's commonly used by researchers and advanced users who need more control over the model architecture.\n",
    "\n",
    "### When to Use Which:\n",
    "- **Sequential API**: Use the Sequential API when you're building simple, linear models with a single input and output, such as feedforward neural networks or simple CNNs.\n",
    "- **Functional API**: Use the Functional API when you need more flexibility and control over the model architecture, such as when building complex models with multiple inputs and outputs, branching, or shared layers.\n",
    "\n",
    "### Example:\n",
    "Here's a simple example of building the same model using both APIs:\n",
    "\n",
    "**Sequential API:**\n",
    "```python\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "**Functional API:**\n",
    "```python\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "inputs = layers.Input(shape=(input_dim,))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "```\n",
    "\n",
    "In this example, both approaches create the same model with a single input and output, but the Functional API provides more flexibility and control over the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                90        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification A)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer([X_train.shape[1],]), # Create input layer with 'input data' neurons\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), # Create hidden layer with 10 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # Create output layer with one neuron and sigmoid activation\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "#Input layer je 8 neuronu -> mam 8 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification B)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/functional)\n",
    "\n",
    "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "hidden = tf.keras.layers.Dense(10)(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "hidden = tf.keras.layers.Dense(1)(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(hidden)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu (TFOpLambda)     (None, 10)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid (TFOpLambda  (None, 1)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with selected optimizer, loss and metrics\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(), # Several other possibilities for optimizers \n",
    "        loss=tf.losses.BinaryCrossentropy(), # Select the proper loss for the task\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()], # Select the proper metrics for the task\n",
    ")\n",
    "\n",
    "\n",
    "#For regression tasks, tf.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Bias of the last layers:\n",
      "[-0.17000008]\n",
      "\n",
      ">>> Kernel of the last layers:\n",
      "[[ 2.2186315 ]\n",
      " [-2.077674  ]\n",
      " [ 0.6896167 ]\n",
      " [ 0.87723047]\n",
      " [-2.413737  ]\n",
      " [-0.7869727 ]\n",
      " [ 2.166464  ]\n",
      " [ 3.1737132 ]\n",
      " [ 1.5944035 ]\n",
      " [ 2.83186   ]]\n",
      "\n",
      ">>> Bias of the first layers:\n",
      "[-1.2135944   0.49064967  1.0362744   1.2408949   0.38448688 -0.24221994\n",
      " -1.0867906  -1.7819648  -0.768613   -1.7855418 ]\n",
      "\n",
      ">>> Kernel of the first layers:\n",
      "[[-7.22754478e-01 -1.13089621e+00  1.30688354e-01  2.63837665e-01\n",
      "   9.08078253e-01  1.58591926e+00 -4.53085452e-01 -4.70656186e-01\n",
      "   3.02479446e-01  1.37053490e+00]\n",
      " [-1.76413159e-03 -3.99489664e-02 -3.13970074e-02  5.16231172e-02\n",
      "  -8.23013857e-03  1.26701146e-01 -3.45270745e-02 -5.55979498e-02\n",
      "  -1.29643148e-02  7.33728483e-02]\n",
      " [-2.77393132e-01  1.23936152e+00  4.24409598e-01 -5.07162035e-01\n",
      "  -1.16471505e+00  9.51085567e-01  9.91107166e-01  4.39952910e-01\n",
      "  -2.23607346e-01 -1.16097200e+00]\n",
      " [ 8.44831765e-01 -7.62415767e-01 -3.75716269e-01  8.97019207e-02\n",
      "   9.88683760e-01 -1.81966349e-01 -9.67874825e-01 -2.05193579e-01\n",
      "  -1.07666218e+00  1.48315892e-01]\n",
      " [ 1.61730568e-03 -1.16909808e-02 -3.62289846e-02 -5.32624312e-02\n",
      "  -2.54432764e-02 -2.34833583e-02 -1.49461452e-03  1.21024260e-02\n",
      "   3.81222703e-02 -1.21886350e-01]\n",
      " [ 9.36780572e-01  9.72088397e-01 -4.73551512e-01  1.91656902e-01\n",
      "  -1.26163352e+00  3.97427231e-01  7.22316265e-01 -4.69462097e-01\n",
      "   1.88221380e-01 -7.98602641e-01]\n",
      " [-1.01986621e-02 -8.34073219e-03 -2.63458341e-02 -3.45732644e-02\n",
      "   3.41681647e-04 -2.48903185e-02 -1.34617165e-02 -2.24140193e-02\n",
      "  -6.29622675e-03 -5.56735508e-02]\n",
      " [-2.01862857e-01 -2.06216168e+00 -1.92856118e-02 -4.38655436e-01\n",
      "   1.53870499e+00  1.95717409e-01 -1.76654267e+00  6.44649565e-01\n",
      "  -9.67557013e-01  8.48272443e-01]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n>>> Bias of the last layers:')\n",
    "print(model.layers[3].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the last layers:') #Kernel refers to the weight matric from the mentinoned layer\n",
    "print(model.layers[3].weights[0].numpy())\n",
    "\n",
    "print('\\n>>> Bias of the first layers:')\n",
    "print(model.layers[1].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the first layers:')\n",
    "print(model.layers[1].weights[0].numpy())\n",
    "\n",
    "#I guess only some init weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 883us/step - loss: 0.7042 - auc: 0.6880 - binary_accuracy: 0.5995\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 909us/step - loss: 0.5118 - auc: 0.8466 - binary_accuracy: 0.7420\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 851us/step - loss: 0.4301 - auc: 0.8918 - binary_accuracy: 0.8129\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 871us/step - loss: 0.3857 - auc: 0.9157 - binary_accuracy: 0.8410\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 891us/step - loss: 0.3543 - auc: 0.9304 - binary_accuracy: 0.8601\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.3296 - auc: 0.9402 - binary_accuracy: 0.8730\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 833us/step - loss: 0.3093 - auc: 0.9469 - binary_accuracy: 0.8846\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 820us/step - loss: 0.2932 - auc: 0.9522 - binary_accuracy: 0.8923\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 849us/step - loss: 0.2814 - auc: 0.9556 - binary_accuracy: 0.8972\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 846us/step - loss: 0.2725 - auc: 0.9581 - binary_accuracy: 0.9007\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 832us/step - loss: 0.2653 - auc: 0.9600 - binary_accuracy: 0.9023\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 839us/step - loss: 0.2594 - auc: 0.9615 - binary_accuracy: 0.9039\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 803us/step - loss: 0.2546 - auc: 0.9631 - binary_accuracy: 0.9057\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 810us/step - loss: 0.2501 - auc: 0.9642 - binary_accuracy: 0.9066\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 824us/step - loss: 0.2460 - auc: 0.9652 - binary_accuracy: 0.9080\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 850us/step - loss: 0.2429 - auc: 0.9660 - binary_accuracy: 0.9088\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 840us/step - loss: 0.2393 - auc: 0.9669 - binary_accuracy: 0.9102\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 921us/step - loss: 0.2362 - auc: 0.9677 - binary_accuracy: 0.9110\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2334 - auc: 0.9685 - binary_accuracy: 0.9125\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2303 - auc: 0.9695 - binary_accuracy: 0.9135\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 864us/step - loss: 0.2270 - auc: 0.9704 - binary_accuracy: 0.9154\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 834us/step - loss: 0.2240 - auc: 0.9712 - binary_accuracy: 0.9165\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 851us/step - loss: 0.2210 - auc: 0.9721 - binary_accuracy: 0.9182\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 881us/step - loss: 0.2186 - auc: 0.9725 - binary_accuracy: 0.9180\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 842us/step - loss: 0.2158 - auc: 0.9734 - binary_accuracy: 0.9198\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 864us/step - loss: 0.2137 - auc: 0.9738 - binary_accuracy: 0.9209\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 850us/step - loss: 0.2113 - auc: 0.9744 - binary_accuracy: 0.9231\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.2091 - auc: 0.9749 - binary_accuracy: 0.9237\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 889us/step - loss: 0.2073 - auc: 0.9753 - binary_accuracy: 0.9233\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 895us/step - loss: 0.2054 - auc: 0.9759 - binary_accuracy: 0.9259\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 829us/step - loss: 0.2037 - auc: 0.9762 - binary_accuracy: 0.9264\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 857us/step - loss: 0.2020 - auc: 0.9767 - binary_accuracy: 0.9264\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 841us/step - loss: 0.2004 - auc: 0.9770 - binary_accuracy: 0.9272\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 846us/step - loss: 0.1990 - auc: 0.9773 - binary_accuracy: 0.9283\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 882us/step - loss: 0.1978 - auc: 0.9776 - binary_accuracy: 0.9302\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 880us/step - loss: 0.1963 - auc: 0.9779 - binary_accuracy: 0.9307\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 858us/step - loss: 0.1950 - auc: 0.9781 - binary_accuracy: 0.9308\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 899us/step - loss: 0.1939 - auc: 0.9783 - binary_accuracy: 0.9318\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.1923 - auc: 0.9786 - binary_accuracy: 0.9334\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 841us/step - loss: 0.1916 - auc: 0.9789 - binary_accuracy: 0.9344\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 847us/step - loss: 0.1904 - auc: 0.9791 - binary_accuracy: 0.9335\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 871us/step - loss: 0.1893 - auc: 0.9793 - binary_accuracy: 0.9353\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 831us/step - loss: 0.1882 - auc: 0.9794 - binary_accuracy: 0.9349\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 912us/step - loss: 0.1874 - auc: 0.9797 - binary_accuracy: 0.9355\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 929us/step - loss: 0.1863 - auc: 0.9798 - binary_accuracy: 0.9370\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 873us/step - loss: 0.1854 - auc: 0.9800 - binary_accuracy: 0.9362\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 891us/step - loss: 0.1846 - auc: 0.9802 - binary_accuracy: 0.9366\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.1835 - auc: 0.9804 - binary_accuracy: 0.9372\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 852us/step - loss: 0.1826 - auc: 0.9804 - binary_accuracy: 0.9380\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 887us/step - loss: 0.1821 - auc: 0.9806 - binary_accuracy: 0.9386\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 828us/step - loss: 0.1812 - auc: 0.9808 - binary_accuracy: 0.9380\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 884us/step - loss: 0.1804 - auc: 0.9809 - binary_accuracy: 0.9391\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 900us/step - loss: 0.1798 - auc: 0.9810 - binary_accuracy: 0.9394\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1790 - auc: 0.9811 - binary_accuracy: 0.9401\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.1786 - auc: 0.9812 - binary_accuracy: 0.9402\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 872us/step - loss: 0.1778 - auc: 0.9814 - binary_accuracy: 0.9404\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 869us/step - loss: 0.1770 - auc: 0.9816 - binary_accuracy: 0.9405\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 839us/step - loss: 0.1765 - auc: 0.9816 - binary_accuracy: 0.9406\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 887us/step - loss: 0.1759 - auc: 0.9817 - binary_accuracy: 0.9423\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 851us/step - loss: 0.1755 - auc: 0.9818 - binary_accuracy: 0.9423\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 911us/step - loss: 0.1748 - auc: 0.9819 - binary_accuracy: 0.9424\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 987us/step - loss: 0.1743 - auc: 0.9819 - binary_accuracy: 0.9426\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 867us/step - loss: 0.1741 - auc: 0.9820 - binary_accuracy: 0.9423\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 878us/step - loss: 0.1734 - auc: 0.9821 - binary_accuracy: 0.9429\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 874us/step - loss: 0.1730 - auc: 0.9822 - binary_accuracy: 0.9430\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 859us/step - loss: 0.1725 - auc: 0.9823 - binary_accuracy: 0.9436\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 851us/step - loss: 0.1721 - auc: 0.9824 - binary_accuracy: 0.9423\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.1718 - auc: 0.9824 - binary_accuracy: 0.9426\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 858us/step - loss: 0.1713 - auc: 0.9825 - binary_accuracy: 0.9439\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 923us/step - loss: 0.1706 - auc: 0.9826 - binary_accuracy: 0.9443\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 881us/step - loss: 0.1708 - auc: 0.9826 - binary_accuracy: 0.9445\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 888us/step - loss: 0.1700 - auc: 0.9827 - binary_accuracy: 0.9442\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 880us/step - loss: 0.1697 - auc: 0.9827 - binary_accuracy: 0.9449\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 869us/step - loss: 0.1694 - auc: 0.9827 - binary_accuracy: 0.9448\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 845us/step - loss: 0.1691 - auc: 0.9827 - binary_accuracy: 0.9452\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 862us/step - loss: 0.1687 - auc: 0.9828 - binary_accuracy: 0.9447\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 886us/step - loss: 0.1684 - auc: 0.9829 - binary_accuracy: 0.9453\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 848us/step - loss: 0.1682 - auc: 0.9829 - binary_accuracy: 0.9456\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 832us/step - loss: 0.1678 - auc: 0.9829 - binary_accuracy: 0.9466\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 864us/step - loss: 0.1675 - auc: 0.9830 - binary_accuracy: 0.9459\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 906us/step - loss: 0.1671 - auc: 0.9829 - binary_accuracy: 0.9456\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 884us/step - loss: 0.1669 - auc: 0.9831 - binary_accuracy: 0.9467\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 928us/step - loss: 0.1668 - auc: 0.9830 - binary_accuracy: 0.9455\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 931us/step - loss: 0.1664 - auc: 0.9831 - binary_accuracy: 0.9459\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 883us/step - loss: 0.1662 - auc: 0.9830 - binary_accuracy: 0.9464\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 859us/step - loss: 0.1658 - auc: 0.9832 - binary_accuracy: 0.9460\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 843us/step - loss: 0.1656 - auc: 0.9833 - binary_accuracy: 0.9457\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 866us/step - loss: 0.1656 - auc: 0.9832 - binary_accuracy: 0.9465\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 836us/step - loss: 0.1652 - auc: 0.9832 - binary_accuracy: 0.9460\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 879us/step - loss: 0.1650 - auc: 0.9833 - binary_accuracy: 0.9466\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 856us/step - loss: 0.1648 - auc: 0.9833 - binary_accuracy: 0.9466\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 855us/step - loss: 0.1642 - auc: 0.9834 - binary_accuracy: 0.9466\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1642 - auc: 0.9835 - binary_accuracy: 0.9471\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1640 - auc: 0.9832 - binary_accuracy: 0.9470\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 926us/step - loss: 0.1639 - auc: 0.9833 - binary_accuracy: 0.9471\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 946us/step - loss: 0.1634 - auc: 0.9835 - binary_accuracy: 0.9473\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.1632 - auc: 0.9835 - binary_accuracy: 0.9474\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1632 - auc: 0.9834 - binary_accuracy: 0.9472\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 894us/step - loss: 0.1628 - auc: 0.9835 - binary_accuracy: 0.9483\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 874us/step - loss: 0.1627 - auc: 0.9836 - binary_accuracy: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2557ad6a7a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with default setting\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1858 - auc: 0.9784 - binary_accuracy: 0.9392\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and predict for the test data\n",
    "model.evaluate(X_test, y_test)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 0.46\n",
      "0 - 0.28\n",
      "0 - 0.17\n",
      "1 - 1.00\n",
      "0 - 0.00\n",
      "0 - 0.01\n",
      "1 - 0.99\n",
      "0 - 0.00\n",
      "1 - 1.00\n",
      "1 - 1.00\n"
     ]
    }
   ],
   "source": [
    "for pred, true in zip(test_pred, y_test[0:10]):\n",
    "    print('{} - {:.2f}'.format(true, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add early stopping and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RegularizedModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid_1 (TFOpLamb  (None, 1)                0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "# Hidden layer with regularization and ReLU\n",
    "hidden = tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "\n",
    "# Output layer with regularization and sigmoid\n",
    "outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.001))(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        loss=tf.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2233 - auc_1: 0.9823 - binary_accuracy: 0.9427 - val_loss: 0.2273 - val_auc_1: 0.9813 - val_binary_accuracy: 0.9403\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2234 - auc_1: 0.9821 - binary_accuracy: 0.9417 - val_loss: 0.2265 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9403\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2232 - auc_1: 0.9823 - binary_accuracy: 0.9427 - val_loss: 0.2276 - val_auc_1: 0.9815 - val_binary_accuracy: 0.9413\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2235 - auc_1: 0.9821 - binary_accuracy: 0.9426 - val_loss: 0.2271 - val_auc_1: 0.9815 - val_binary_accuracy: 0.9419\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2231 - auc_1: 0.9823 - binary_accuracy: 0.9426 - val_loss: 0.2274 - val_auc_1: 0.9813 - val_binary_accuracy: 0.9403\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2233 - auc_1: 0.9822 - binary_accuracy: 0.9422 - val_loss: 0.2272 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9400\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2231 - auc_1: 0.9823 - binary_accuracy: 0.9423 - val_loss: 0.2270 - val_auc_1: 0.9813 - val_binary_accuracy: 0.9391\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2231 - auc_1: 0.9823 - binary_accuracy: 0.9432 - val_loss: 0.2275 - val_auc_1: 0.9811 - val_binary_accuracy: 0.9409\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2230 - auc_1: 0.9822 - binary_accuracy: 0.9417 - val_loss: 0.2273 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9391\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2229 - auc_1: 0.9823 - binary_accuracy: 0.9423 - val_loss: 0.2277 - val_auc_1: 0.9814 - val_binary_accuracy: 0.9403\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2232 - auc_1: 0.9823 - binary_accuracy: 0.9432 - val_loss: 0.2274 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9403\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.2230 - auc_1: 0.9823 - binary_accuracy: 0.9431 - val_loss: 0.2278 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2557e819600>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "#patience = if not improving over 10 epochs stop, restore_best_weights = remembers its best results\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_dev, y_dev), # for evaluating the model at the end of each epoch, monitor on unseen data\n",
    "          callbacks=[early_call])\n",
    "\n",
    "#Train\n",
    "#loss: 0.2563 (binary_entropy - want smaller numero)\n",
    "#auc_1: 0.9689 (auc of the train - bigger is better)\n",
    "#binary_accuracy: 0.9093 #proportion of correctly classified instances Correct/All data\n",
    "\n",
    "#Validation set\n",
    "#val_loss: 0.2569 \n",
    "#val_auc_1: 0.9687\n",
    "#val_binary_accuracy: 0.9053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape\n",
    "y_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch and Tensorboard\n",
    "Run gridsearch over hidden layer size, L2 regularization, activation, check the outputs in Tensorboard\n",
    "\n",
    "I recommend not to run Tensorboard from Jupyter notebook but from terminal directly\n",
    "\n",
    "use \"tensorboard --logdir logs\" in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hidden_sizes = [2, 5, 10, 20, 50]\n",
    "# l2_regs = [0.01, 0.001, 0.0001]\n",
    "# activations = ['relu', 'tanh']\n",
    "\n",
    "hidden_sizes = [2, 5]\n",
    "l2_regs = [0.01]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', patience=10, restore_best_weights=True)\n",
    "\n",
    "for activation in activations:\n",
    "    for l2_reg in l2_regs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            if activation == 'relu':\n",
    "                activate = tf.keras.activations.relu\n",
    "            elif activation == 'tanh':\n",
    "                activate = tf.keras.activations.tanh\n",
    "\n",
    "            # Create Tensorboard Callback\n",
    "            param_string = 'act-{},l2-{},hs-{}'.format(activation, l2_reg, hidden_size)\n",
    "            log_dir = 'logs/binary_classification_test/' + param_string\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "            # Input layer\n",
    "            inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "            # Hidden layer with regularization and ReLU\n",
    "            hidden = tf.keras.layers.Dense(hidden_size, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs)\n",
    "            hidden = activate(hidden)\n",
    "\n",
    "            # Output layer with regularization and sigmoid\n",
    "            outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(hidden)\n",
    "            outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.BinaryCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.AUC(name='AUC'), tf.keras.metrics.BinaryAccuracy()],\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_data=(X_dev, y_dev),\n",
    "                      callbacks=[early_call, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have three subsets—training, validation, and test—the distribution of your data among these sets needs to balance training efficiency, model tuning, and final performance evaluation. Here's a detailed guideline on how to split your data:\r\n",
    "\r\n",
    "### Standard Splits:\r\n",
    "1. **Training Set**: Typically, 70-80% of the dataset.\r\n",
    "2. **Validation Set**: Usually, 10-15% of the dataset.\r\n",
    "3. **Test Set**: Commonly, 10-15% of the dataset.\r\n",
    "\r\n",
    "### Example Distribution:\r\n",
    "For a dataset of 100,000 samples:\r\n",
    "- **Training Set (80%)**: 80,000 samples\r\n",
    "- **Validation Set (10%)**: 10,000 samples\r\n",
    "- **Test Set (10%)**: 10,000 samples\r\n",
    "\r\n",
    "### Purpose of Each Set:\r\n",
    "1. **Training Set**:\r\n",
    "   - Used to train the model.\r\n",
    "   - The model learns from this data by adjusting weights based on the loss function.\r\n",
    "\r\n",
    "2. **Validation Set**:\r\n",
    "   - Used to tune hyperparameters and make decisions about model architecture.\r\n",
    "   - Helps to monitor for overfitting by evaluating the model at each epoch during training.\r\n",
    "   - Not used for training but for model selection and early stopping.\r\n",
    "\r\n",
    "3. **Test Set**:\r\n",
    "   - Used for final evaluation after the model is trained and validated.\r\n",
    "   - Provides an unbiased estimate of model performance on unseen data.\r\n",
    "   - Should only be used once to avoid overfitting to the test data.\r\n",
    "\r\n",
    "### Steps for Splitting Data:\r\n",
    "1. **Initial Split**:\r\n",
    "   - First, split your data into training (80%) and temporary (20%) sets.\r\n",
    "\r\n",
    "2. **Second Split**:\r\n",
    "   - Then, split the temporary set into validation (50% of the temporary set, i.e., 10% of the original data) and test (50% of the temporary set, i.e., 10% of the original data) sets.\r\n",
    "\r\n",
    "### Considerations:\r\n",
    "- **Stratification**: Ensure that splits are stratified, especially in classification tasks, to maintain the same proportion of classes in each subset.\r\n",
    "- **Shuffling**: Randomly shuffle the data before splitting to ensure that the splits are representative of the overall dataset.\r\n",
    "- **Data Leakage**: Ensure that no data from the test set is used during training or validation to prevent data leakage and overfitting.\r\n",
    "\r\n",
    "### Code Example in Python:\r\n",
    "Here’s how you might implement this in Python using `train_test_split` from `sklearn`:\r\n",
    "\r\n",
    "```python\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# Assuming X and y are your features and labels\r\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\r\n",
    "\r\n",
    "# Further split the temporary set into validation and test sets\r\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\r\n",
    "\r\n",
    "print(f\"Training set size: {len(X_train)}\")\r\n",
    "print(f\"Validation set size: {len(X_val)}\")\r\n",
    "print(f\"Test set size: {len(X_test)}\")\r\n",
    "```\r\n",
    "\r\n",
    "### Final Thoughts:\r\n",
    "The exact proportions might vary based on your specific needs and the size of your dataset, but following these guidelines will help you to effectively train, validate, and test your model while minimizing the risk of overfitting and ensuring that performance metrics are reliable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
